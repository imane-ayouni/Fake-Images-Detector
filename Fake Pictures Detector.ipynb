{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19246cf",
   "metadata": {},
   "source": [
    "# Fake pictures detector "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c6f4e",
   "metadata": {},
   "source": [
    "## Topic\n",
    "\n",
    "In this project, I will be going through many real people pictures and fake photoshop made pictures, using dimensionality reduction technique, more specifically PCA, reduce the dimendion of the pictures and then apply classification algorithms on them. The row pictures are downloaded and transformed into arrays, only one color channel is kept with the values at each pixel stored into an array, PCA is then apply twice, first time to reduce the photo matrices into their 3 principal components and second to reduce those 3 components in to one principal components which contains 50% of the information in the picture.\n",
    "Different classification algorithms are then applied on the decomposed matrices to try and predict whether a certain picture is real or fake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceecf01",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Reduce the dimension of the photos\n",
    "- Apply classification algorithms to determine whether a picture is real or fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18a40d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Importing Libraries\n",
    "- Quick look at the dataset\n",
    "- Data pre-processing\n",
    "- Logistic Regression\n",
    "- Naive Bayes Classifier\n",
    "- Support Vector Machines\n",
    "- XGBoost Classifier\n",
    "- K Nearest Neighbours\n",
    "- Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9248c",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.image as mplib \n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import  classification_report, confusion_matrix,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff2dc0",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "The dataset is two folders containing real images of different people and photoshop made images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c15b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get two lists containing the names of the files\n",
    "list_real = os.listdir(r\"C:\\Users\\imane\\OneDrive\\Desktop\\eigenfaces\\training_real\")\n",
    "list_fake = os.listdir(r\"C:\\Users\\imane\\OneDrive\\Desktop\\eigenfaces\\training_fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1677d",
   "metadata": {},
   "source": [
    "I have 1081 images of real people and 960 images of photoshoped fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to the image folders\n",
    "path_real = r\"C:\\Users\\imane\\OneDrive\\Desktop\\eigenfaces\\training_real\"\n",
    "path_fake = r\"C:\\Users\\imane\\OneDrive\\Desktop\\eigenfaces\\training_fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4395b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the paths to real images\n",
    "pics_real = [os.path.join(path_real, i) for i in list_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the paths to fake images\n",
    "pics_fake = [os.path.join(path_fake, i) for i in list_fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a47c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the paths to the real photos\n",
    "paths_real = [os.path.join(path_real,i) for i in list_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b526a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the paths to the fake photos\n",
    "paths_fake = [os.path.join(path_fake,i) for i in list_fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5430505",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_real = []\n",
    "for p in paths_real:\n",
    "    img = Image.open(p)\n",
    "    array = np.asarray(img)\n",
    "    arrays_real.append(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebafba",
   "metadata": {},
   "source": [
    "In this part, I opened every pictures in the real picture folder, transformed it into an array and stored all the arrays in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0534a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_fake = []\n",
    "for p in paths_fake:\n",
    "    img = Image.open(p)\n",
    "    array = np.asarray(img)\n",
    "    arrays_fake.append(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8c6b2",
   "metadata": {},
   "source": [
    "I did the same for fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d73dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = arrays_real[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of images\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42253f31",
   "metadata": {},
   "source": [
    "The images are in shape 600*600*3 , meaning length and width of 600 times the three color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the picture into its 3 channels\n",
    "blue,green,red = cv2.split(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883bf20",
   "metadata": {},
   "source": [
    "Here I plotted the picture in its 3 channels red blue and green."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85937fbf",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_real = []\n",
    "g_real = []\n",
    "r_real = []\n",
    "for a in arrays_real:\n",
    "    blue, green, red = cv2.split(a)\n",
    "    b_real.append(blue)\n",
    "    g_real.append(green)\n",
    "    r_real.append(red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_fake = []\n",
    "g_fake = []\n",
    "r_fake = []\n",
    "for a in arrays_fake:\n",
    "    blue, green, red = cv2.split(a)\n",
    "    b_fake.append(blue)\n",
    "    g_fake.append(green)\n",
    "    r_fake.append(red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d71ed9",
   "metadata": {},
   "source": [
    "In the above, I iterated through every picture array, split it into the three channels and stored each channels information into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f446f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b93c00",
   "metadata": {},
   "source": [
    "I then printed channel red for the real pictures and channel green for the fake pictures, the lists contains pixel data in the subsequant channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_real[0] = r_real[0]/255\n",
    "r_real[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a040e",
   "metadata": {},
   "source": [
    "While experimenting with one picture, I first regularised the pixel data by deviding the array by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3 = PCA(n_components=3)\n",
    "pca_3.fit_transform(r_real[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69121cb8",
   "metadata": {},
   "source": [
    "I then applied PCA with 3 components on the regularised array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ration of variance -  identify how significant is each principal component \n",
    "print(pca_3.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43c939",
   "metadata": {},
   "source": [
    "Here I printed the eigenvalues of the first 3 components, we see that the first principal components only holds 0,24 of the information in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_3.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2def0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the principal components (eigenvectors)\n",
    "pca_3.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e762633",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1 = PCA(n_components = 1)\n",
    "pca_1.fit_transform(pca_3.components_)\n",
    "pca_1.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd26d1",
   "metadata": {},
   "source": [
    "Then I applied a second PCA on my 3 principal components to try and reduce the picture into only one array. We see that the only principal components holds 50% of the information in the data, which is not bad considering how much dementiality reduction has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3 = PCA(n_components = 3)\n",
    "pca_1 = PCA(n_components = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52123a9",
   "metadata": {},
   "source": [
    "Here I created two PCAs one with 3 princiapl components and the second with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_real = []\n",
    "for a in r_real:\n",
    "    a = a/255\n",
    "    pca_3.fit_transform(a)    \n",
    "    pca_1.fit_transform(pca_3.components_)    \n",
    "    features_real.append(pca_1.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33f528",
   "metadata": {},
   "source": [
    "Choosing only the red channel, I regularised every picture array, transformed it with PCA and kept its three components, reapplied PCA and got only the one principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features list into an array\n",
    "features_real = np.array(features_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225aa9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of the array\n",
    "features_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only two dimensions in the array\n",
    "features_real = np.squeeze(features_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901cb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139dacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the array into a pandas dataframe\n",
    "df_real = pd.DataFrame(features_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4546ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the target column, 1 for real\n",
    "df_real[\"target\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c30e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1487bff",
   "metadata": {},
   "source": [
    "In the above, I transformed every picture into one array line and stored it in a pandas dataframe, then added the target feature which is 1 for real pictures and 0 for fake pictures. Below I did the same for fake pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16353aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fake = []\n",
    "for a in r_fake:\n",
    "    a = a/255\n",
    "    pca_3.fit_transform(a)    \n",
    "    pca_1.fit_transform(pca_3.components_)    \n",
    "    features_fake.append(pca_1.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81436349",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fake = np.array(features_fake)\n",
    "features_fake = np.squeeze(features_fake)\n",
    "df_fake = pd.DataFrame(features_fake)\n",
    "df_fake[\"target\"] = 0\n",
    "df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_real.append(df_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30d61a",
   "metadata": {},
   "source": [
    "I added the real pictures dataframe to the fake pictures dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb53f3d",
   "metadata": {},
   "source": [
    "Then shuffled the rows with target 1 with eows with target 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4675bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2163bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target from the dataset\n",
    "target = df['target'].copy()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c122ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c065ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset for training and testing samples\n",
    "X_train, X_test, y_train, y_test = train_test_split( df, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cf710",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = pd.DataFrame(y_train)\n",
    "cat_train[\"count\"] = 1\n",
    "cat_train = cat_train.groupby(\"target\").sum().reset_index()\n",
    "x = cat_train[\"target\"]\n",
    "y = cat_train[\"count\"]\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8aa218",
   "metadata": {},
   "source": [
    "Here I just wanted to make sure that the amount of real photos in the training set is not too far from the number of fake photos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80017339",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4746d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7161642",
   "metadata": {},
   "source": [
    "running the grid search to find best parameters for the base line model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters\n",
    "logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data\n",
    "lr = LogisticRegression(C= 0.001, penalty='l2')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on training\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aefc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on test set\n",
    "acc_lr = lr.score(X_test, y_test)\n",
    "acc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_lr = f1_score(y_test, lr_pred)\n",
    "f1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad09976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_lr = classification_report(y_test,lr_pred )\n",
    "print(cr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d9c02b",
   "metadata": {},
   "source": [
    "The classification report shows a poor job done by my base line model, expecially when it comes to fake photos detection. The accuracy of the model didn't change much between training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lr = confusion_matrix(y_test,lr_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_lr)\n",
    "ax.grid(False)# defining parameter range\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_lr[i, j], ha='center', va='center', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42273659",
   "metadata": {},
   "source": [
    "Here the model basically predicted everything as real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2325a2d",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ed27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                 param_grid=params_NB, \n",
    "                 verbose=1, \n",
    "                 scoring='accuracy') \n",
    "gs_NB.fit(X_train, y_train)\n",
    "\n",
    "gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc46a64",
   "metadata": {},
   "source": [
    "Performing a quick grid search to determine best params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac74ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB(var_smoothing= 1.0)\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c51a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = nb.score(X_test, y_test)\n",
    "acc_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba233973",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_nb = f1_score(y_test, nb_pred)\n",
    "f1_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_nb = classification_report(y_test,nb_pred )\n",
    "print(cr_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c44e25",
   "metadata": {},
   "source": [
    "The results of Naive Bayes are more balances then those of Logistic regression, although the accuracy droped a bit with NB, its F1 score, ie average of precision and recall, have balances out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_nb = confusion_matrix(y_test,nb_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_nb)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_nb[i, j], ha='center', va='center', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d0506",
   "metadata": {},
   "source": [
    "The confusion matrix shows better performance on detecting real photos then fake one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec43f2",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c665bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249578a",
   "metadata": {},
   "source": [
    "Here I ran a grid serch for the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C= 0.1, gamma = 1, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed326c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f03c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svc = svc.score(X_test, y_test)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svc = f1_score(y_test, svc_pred)\n",
    "f1_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818edd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_svc = classification_report(y_test,svc_pred )\n",
    "print(cr_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43914b",
   "metadata": {},
   "source": [
    "The performance of SVC is poor and similar to that of logistic regression, it's normal because I have 600 features which can though for an SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svc = confusion_matrix(y_test,svc_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_svc)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_svc[i, j], ha='center', va='center', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787f2ba",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59376565",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57febaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_xgb = xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_xgb = f1_score(y_test, xgb_pred)\n",
    "f1_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_xgb = classification_report(y_test,xgb_pred )\n",
    "print(cr_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb453c7",
   "metadata": {},
   "source": [
    "The accuracy of XGB is 1 on the training data, which means that the algo has most probably overfit the training data, its accuracy on the test set is much more reasonable. In terms of F1 score, it's average and slightly better for detecting real pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb = confusion_matrix(y_test,xgb_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_xgb)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_xgb[i, j], ha='center', va='center', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b45342",
   "metadata": {},
   "source": [
    "## K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23035120",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183070c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe601f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bea3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35833b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc1159",
   "metadata": {},
   "source": [
    "The grid search has determined 20 neighbours to be the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80163ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_knn = f1_score(y_test, knn_pred)\n",
    "f1_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_knn = classification_report(y_test,knn_pred )\n",
    "print(cr_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710ac4f",
   "metadata": {},
   "source": [
    "The accuracy of KNN is average as well as its F1 score, although it has done slightly better at detecting real pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71afe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn = confusion_matrix(y_test,knn_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_knn)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_knn[i, j], ha='center', va='center', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f31ae",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88383068",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "       \"max_depth\": range(5,10),\n",
    "       \"min_samples_split\": range(40,50),\n",
    "       \"min_samples_leaf\": range(80,90)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(dec_tree, param_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f570632",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 5,min_samples_leaf = 80, min_samples_split = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6cae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac116a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59958bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508eeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tree = tree.score(X_test, y_test)\n",
    "acc_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_tree = f1_score(y_test, tree_pred)\n",
    "f1_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e57f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_tree = classification_report(y_test,tree_pred )\n",
    "print(cr_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfaec8a",
   "metadata": {},
   "source": [
    "The combined F1 score for both classes is higher than other algorithms although the Decision Tree also did better on real pictures than detecting fake one, the model didn't overfit and its accuracy on the test set is average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_tree = confusion_matrix(y_test,tree_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_tree)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_tree[i, j], ha='center', va='center', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae6b7c",
   "metadata": {},
   "source": [
    "The Decision tree did also better at detecting real images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb421d14",
   "metadata": {},
   "source": [
    "## Models comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [acc_lr, acc_nb, acc_svc, acc_xgb, acc_knn, acc_tree]\n",
    "f1 = [f1_lr, f1_nb, f1_svc, f1_xgb, f1_knn, f1_tree]\n",
    "models = [\"LR\", \"NB\", \"SVC\", \"XGB\", \"KNN\", \"DT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50865274",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_axis = np.arange(len(models))\n",
    "plt.figure(figsize=(8, 8))  \n",
    "plt.bar(X_axis - 0.2, acc , 0.4, label = 'Accuracy')\n",
    "plt.bar(X_axis + 0.2, f1, 0.4, label = 'F1 score')\n",
    "  \n",
    "plt.xticks(X_axis, models)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.title(\"Performance of Models\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8815851",
   "metadata": {},
   "source": [
    "The above plot shows the performance of the different algorithms used. Now from first glance, it seems that Logistic regression and SVC are doing the best jobs, but that's only because these two models can only predict fairly well on real images, while their predictions on fake pictures are extremely weak. Decision Tree looks like the next thing to look at, its accuracy is about average and its average F1 score is influenced by the F1 score for real pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b97c3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook I tried to build models capable of detecting fake pictures. Firstly, I tried to reduce the dimensionality of the images using PCA, then I attempted with different classification algorithms. The results of my models are average if not too bad (like LR and SVC), and I can argue its because of :\n",
    "- The method of pre-processing I used: maybe the PCA that kept only half of the information  in the picture has let go of so much information necessary for the models to differentiate between the two classes.\n",
    "- Machine learning algorithms are not able to handle well this particular problem and that neural networks should be given a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f904e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
